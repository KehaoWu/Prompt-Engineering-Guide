# 引言提示

提示工程是一种相对较新的专业，旨在开发和优化提示以有效地利用语言模型（LM）来进行各种应用和研究主题。提示工程技能有助于更好地了解大型语言模型（LLMs）的能力和限制。研究人员使用提示工程来提高LLMs在各种常见和复杂任务中的能力，例如问答和算术推理。开发人员使用提示工程设计强大且有效的提示技术，与LLMs和其他工具进行接口交互。

本指南涵盖了标准提示的基础知识，提供了如何使用提示与大型语言模型（LLM）进行交互和指导的大致想法。

所有示例都使用`gpt-3.5-turbo`进行测试（使用OpenAI的playground），除非另有规定。它使用默认配置，例如`temperature=0.7`和`top-p=1`。


主题：

- [基本提示](#基本提示)
- [关于LLM设置的说明](#关于LLM设置的说明)
- [标准提示](#标准提示)
- [提示要素](#提示要素)
- [设计提示的一般性建议](#设计提示的一般性建议)

---

## 基本提示

你现在可以通过提示实现很多操作，但结果的质量取决于你提供的信息量。提示可以包含像传递给模型的`指令`或`问题`之类的信息，并包括其他细节，如`输入`或`示例`。

以下是一个简单提示的基本示例：

**提示**
```
天空是
```

**输出：**
```
地球上空气中的气体和尘埃颗粒组成的大气层，其中主要成分是氮气和氧气，占据了大气的约99%。天空呈现出蓝色或紫色的颜色，这是由于太阳光在进入大气层时，被散射的结果。此外，天空中还有云朵、太阳、月亮和星星等自然景观。天空对人类的生活和文化都有着深刻的影响，被广泛用于诗歌、绘画、摄影等艺术领域。
```

正如您所看到的，“语言模型”输出了一系列可用上下文“天空是”衔接的字符串。输出的结果可能出乎我们所料，并且距离我们想要完成的任务有所差距。

这个基本的例子还突显了需要提供更多背景或说明，以便明确我们想要实现的具体内容。

让我们试着把它改进一下：

**提示：**
```
完成句子：

天空是
```

**输出：**


```
蓝色的
```

这样是不是更好呢？好的，我们让模型完成了这个句子，结果看起来好多了，因为它完全按照我们告诉它的要求（“完成这个句子”）来做。这种设计最佳提示来指导模型完成任务的方法被称为**提示工程**。


上面的例子是LLMs今天所能实现的基本示例。今天的LLMs能够执行各种高级任务，包括文本摘要、数学推理和代码生成。

---

## 关于LLM设置的说明

使用提示时，您将通过 API 或直接与 LLM 进行交互。您可以配置一些参数，以获取不同的提示结果。

**Temperature** - 简而言之，温度越低，结果就越具决定性，因为最有可能的下一个标记总是被选择。增加温度可能会导致更多的随机性，鼓励更多不同或创造性的输出。我们本质上是增加了其他可能标记的权重。在应用方面，我们可能希望在类似基于事实的问答中使用较低的温度，以鼓励更多客观、简洁的回答。对于诗歌生成或其他创意任务，增加温度可能是有益的。




**Top_p** - 同样地，使用top_p时，一种名为“核心采样”的温度采样技术，您可以控制模型在生成响应时的确定性。如果您正在寻找精确和事实上的答案，请保持较低。如果您正在寻找更多样化的响应，请增加至更高的值。

一般建议是改变其中一个而不是两个。

在开始一些基本示例之前，请记住，您的结果可能会根据您使用的LLM版本而有所不同。

---

## 标准提示

我们已经尝试了一个非常简单的提示符。标准提示符具有以下格式：

```
<问题>?
```

这可以按照许多质量保证数据集中的标准转换为QA格式，如下所示：

```
Q: <问题>?
A:
```

鉴于上述标准格式，一种流行有效的提示技术被称为 few-shot prompting（译者注：少样本学习），其中我们提供示例。Few-shot prompts 的格式如下：


```
<问题>?
<答案>

<问题>?
<答案>

<问题>?
<答案>

<问题>?
```


而且你已经可以猜到它的QA格式版本会是这样的：

```
Q: <问题>?
A: <答案>


Q: <问题>?
A: <答案>

Q: <问题>?
A: <答案>

Q: <问题>?
```

请记住，并非必须使用 QA 格式。格式取决于手头的任务。例如，您可以执行简单的分类任务并提供演示任务的示例，如下所示：

**提示：**
```
太棒了 // 正面
不太好 // 负面
这个表演真好看 // 正面
这个剧演的不好 // 
```

**输出：**
```
这个剧演的不太好。// 负面
```

Few-shot prompts 使得上下文学习成为可能，即语言模型仅需少量示例即可学习任务的能力。在即将发布的指南中，我们将看到更多此类情景的实践。


--- 

## 提示要素

随着我们涵盖越来越多的实例和应用程序，这些应用程序可能涉及提示工程，您将会注意到有某些要素构成一个提示。


一个提示可以包含以下任何组件:`


**指示** - 您希望模型执行的特定任务或指示
**上下文** - 可能涉及外部信息或附加上下文，可以引导模型产生更好的响应。
**输入数据** - 是我们感兴趣寻找答案的输入或问题。
**输出指示器** - 指示输出的类型或格式。

并非所有组件都需要用于提示，格式取决于当前任务。在接下来的指南中，我们将涉及更多具体的例子。

---

## 设计提示的一般性建议

以下是在设计提示时需要记住的一些提示：

### 开始简单

作为你开始设计提示的时候，你应该牢记这是一个迭代过程，需要大量的实验来获得最佳效果。使用像OpenAI或Cohere这样的简单工具界面是一个不错的起点。

您可以从简单的提示开始，随着获得更好的结果，逐步添加更多元素和上下文。在此过程中版本控制您的提示尤为重要。当阅读指南时，您将看到许多例子，其中特定性、简洁性和简明性通常会给您带来更好的结果。

当你有包含多个子任务的大型任务时，可以尝试将任务分解成简单的子任务，并在获得更好的结果时持续构建。这可以避免在开始进行任务设计时添加过多的复杂性。

### 指令

您可以使用指令来指示模型您想要实现的功能，例如“写入”，“分类”，“概述”，“翻译”，“排序”等等，从而设计各种简单任务的有效提示。

请记住，您还需要进行大量的实验，以确定哪种方法效果最好。尝试使用不同的关键词、上下文和数据来测试不同的指令，看看什么对您特定的用例和任务最有效。通常，上下文与您要执行的任务越具体和相关，效果越好。在即将发布的指南中，我们将介绍采样和添加更多上下文的重要性。 

```
请记住，您还需要进行大量的实验，以确定哪种方法效果最好。尝试使用不同的关键词、上下文和数据来测试不同的指令，看看什么对您特定的用例和任务最有效。通常，上下文与您要执行的任务越具体和相关，效果越好。在即将发布的指南中，我们将介绍采样和添加更多上下文的重要性。 
```

建议将说明放在提示的开头，同时建议使用明显的分隔符，例如“###”，以分离说明和上下文。

例如：

*提示：*
```
### 指示 ###

翻译以下文本成西班牙语：

文本：hello!
```

**输出:**
```
Hola!
```

### 特异性

非常清晰地说明您希望模型执行的指示和任务。提示越详细和详细，结果就越好。当您寻求期望的结果或生成风格时，这尤其重要。没有特定的令牌或关键字可以带来更好的结果。更重要的是具有良好的格式和详细的提示。事实上，在提示中提供示例非常有效，可以以特定格式获得所需的输出。

当设计提示时，您还应该考虑提示的长度，因为其长度存在限制。考虑提示的具体和详细程度是需要考虑的事情。过多的不必要细节并不一定是好方法，细节应该是相关的并有助于完成任务。这是您需要进行大量实验的事情。我们鼓励大量的实验和迭代，以优化应用程序的提示。

作为一个例子，让我们尝试一个简单的提示来从一段文本中提取特定信息。

**提示：**
```
提取以下文本中的地名。

目标格式: 
地点：<公司名称的逗号分隔列表>

输入：虽然这些发展对研究人员很鼓舞，但仍有许多谜团。来自里斯本Champalimaud未知中心的神经免疫学家Henrique Veiga-Fernandes表示：“大脑和周围效应之间经常存在一个黑匣子。如果我们想在治疗上使用它，实际上需要理解机制。”
```

**输出：**
```
地点：里斯本, Champalimaud未知中心
```

输入文本是从 [这篇Nature文章](https://www.nature.com/articles/d41586-023-00509-z) 获取的。


### 避免不准确性

考虑到上述有关详细描述和改善格式的技巧，很容易陷入想要过于聪明地处理提示并潜在地造成不精确描述的陷阱中。通常最好是具体而直接。这里的类比非常类似于有效的沟通-信息越直接，传达的信息就越有效。


例如，你可能会有兴趣学习提示工程的概念。你可以尝试类似这样的内容：

```
解释概念提示工程。保持解释简短，只用几句话，不要过于描述。
```

从上面的提示中并不清楚要使用多少句子和什么样的风格。您可能仍然能够获得不错的回答，但更好的提示应该非常具体、简洁和直接。比如：

```
使用2-3句话向高中学生解释"提示工程"的概念。 
```





### 做还是不做？

另一个常见的提示是在设计提示时避免与其说不要做什么，不如说做什么。这鼓励更具体和关注细节，从而得到良好的模型响应。

以下是一个电影推荐聊天机器人的例子，我写的指示太过关注于避免的事情，导致机器人完全未能如愿工作。

**提示:**
```
以下是向客户推荐电影的智能客服。不要询问兴趣爱好。不要询问个人信息。

客户：请根据我的兴趣推荐一部电影。
智能客服：
```

**输出：**
```
非常好，请问您希望观看哪个类型的电影呢？比如动作片、喜剧片、爱情片、科幻片等等。
```


以下是更好的提示：

**提示：**
```
以下是向客户推荐电影的智能客服。该智能客服负责推荐全球最热门的电影之一。它应避免询问用户的偏好并且不要询问个人信息。如果智能客服没有电影可以推荐，则应回复“抱歉，今天无法推荐电影”。

客户：请根据我的兴趣推荐一部电影。
智能客服：
```





**输出：**
```
非常抱歉，本次推荐是全球最热门的电影之一，我们无法根据您的个人兴趣推荐电影。这部电影名为《泰坦尼克号》，讲述了一对跨越社会阶层的恋人在船上经历的爱情故事。如果您还有其他疑问或需求，请告诉我们。
```

以上部分示例源自["OpenAI API最佳实践中的提示工程"文章](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)。

---
[下一节（基本提示）]（./prompts-basic-usage.md）